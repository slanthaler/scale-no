{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f8529bc-5eca-4582-a263-0973dcf47a7d",
   "metadata": {},
   "source": [
    "The differential formulation of the self-consistency constraint requires \n",
    "enforcing of an equation of the form\n",
    "\n",
    "$\n",
    "v_G(x) = \\dfrac{\\partial G(a,g)(x)}{\\partial a(y)} v_a(y) + \\dfrac{\\partial G(a,g)(x)}{\\partial g(\\sigma)} v_G(\\sigma)\n",
    "$\n",
    "\n",
    "where $v_a(y) = y\\cdot \\nabla_y a(y)$ and $v_G(\\sigma) = \\sigma\\cdot\\nabla_y G(a,g)(\\sigma)$ are defined \n",
    "on $\\Omega$ and the boundary $\\partial \\Omega$, respectively.\n",
    "\n",
    "The terms $\\dfrac{\\partial G}{\\partial a} v_a$  and  $\\dfrac{\\partial G}{\\partial g} v_G$ are directional derivatives of the model $G$ in the direction of $v_a$ and $v_G$.\n",
    "\n",
    "It seems computation of such directional derivatives is supported by pytorch!\n",
    "- https://pytorch.org/tutorials/intermediate/forward_ad_usage.html\n",
    "- This blog-entry discusses performance of different possibilities (but may be outdated -- running code from there, I get deprecated warnings): https://leimao.github.io/blog/PyTorch-Automatic-Differentiation/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df26cdb3-3c7c-4860-8f32-4e9b5a4a0079",
   "metadata": {},
   "source": [
    "Fromt the pytorch tutorial: uses functorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32833a15-2cbe-4685-b514-7e3bfee55110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checks successful!\n"
     ]
    }
   ],
   "source": [
    "import functorch as ft\n",
    "\n",
    "# value\n",
    "primal0 = torch.randn(10, 10)\n",
    "primal1 = torch.randn(10, 10)\n",
    "\n",
    "# direction vector\n",
    "tangent0 = torch.ones(10, 10)\n",
    "tangent1 = torch.ones(10, 10)\n",
    "\n",
    "# function to be differentiated\n",
    "def fn(x, y):\n",
    "    return x ** 2 + y ** 2\n",
    "\n",
    "# note: the jacobian-vector-product with (1,1) for the above fn is 2*(x+y),\n",
    "#       i.e. fn_jac(x,y)[(1,1)] = 2*(x+y)\n",
    "\n",
    "# Here is a basic example to compute the JVP of the above function.\n",
    "# The ``jvp(func, primals, tangents)`` returns ``func(*primals)`` as well as the\n",
    "# computed Jacobian-vector product (JVP). Each primal must be associated with a tangent of the same shape.\n",
    "primal_out, tangent_out = ft.jvp(fn, (primal0, primal1), (tangent0, tangent1))\n",
    "\n",
    "# check that we get expected results\n",
    "def fn_directional(x, y, vx, vy):\n",
    "    return 2*x*vx + 2*y*vy\n",
    "\n",
    "primal_check, tangent_check = fn(primal0,primal1), fn_directional(primal0,primal1,tangent0,tangent1)\n",
    "\n",
    "assert torch.allclose(primal_out,primal_check), 'primals wrong??'\n",
    "assert torch.allclose(tangent_out,tangent_check), 'tangents wrong??'\n",
    "print('Checks successful!')\n",
    "\n",
    "\n",
    "# ``functorch.jvp`` requires every primal to be associated with a tangent.\n",
    "# If we only want to associate certain inputs to `fn` with tangents,\n",
    "# then we'll need to create a new function that captures inputs without tangents:\n",
    "primal = torch.randn(10, 10)\n",
    "tangent = torch.randn(10, 10)\n",
    "y = torch.randn(10, 10)\n",
    "\n",
    "# the following computes a partial derivative in only one direction\n",
    "import functools\n",
    "new_fn = functools.partial(fn, y=y)\n",
    "primal_out, tangent_out = ft.jvp(new_fn, (primal,), (tangent,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babcc230-916b-467a-b20e-7680425a240a",
   "metadata": {},
   "source": [
    "### It seems, the way to implement the self-consistency constraint for FNO would be as follows(?)\n",
    "\n",
    "$\n",
    "v_G(x) = \\dfrac{\\partial G(a,g)(x)}{\\partial a(y)} v_a(y) + \\dfrac{\\partial G(a,g)(x)}{\\partial g(\\sigma)} v_G(\\sigma)\n",
    "$\n",
    "\n",
    "where $v_a(y) = y\\cdot \\nabla_y a(y)$ and $v_G(\\sigma) = \\sigma\\cdot\\nabla_y G(a,g)(\\sigma)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9caa1bc7-23e0-4659-ad43-53b1c0ca0d7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# assume we have access to:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 1. a function xDx computing (approximate) radial derivative of input\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 2. a function restriction computing the restriction of function to boundary\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m G \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m(a,g)\n\u001b[1;32m      7\u001b[0m tangent_a \u001b[38;5;241m=\u001b[39m xDx(a)\n\u001b[1;32m      8\u001b[0m tangent_g \u001b[38;5;241m=\u001b[39m restriction(xDx(G))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# assume we have access to:\n",
    "# 1. a function \"xDx\" computing (approximate) radial derivative of input\n",
    "# 2. a function \"restriction\" computing the restriction of function to boundary\n",
    "\n",
    "import functorch as ft\n",
    "\n",
    "#\n",
    "G = model(a,g)\n",
    "tangent_a = xDx(a)\n",
    "tangent_g = restriction(xDx(G))\n",
    "\n",
    "#\n",
    "LHS = tangent_G\n",
    "_, RHS = ft.jvp(model, (a,g), (tangent_a, tangent_g))\n",
    "\n",
    "#\n",
    "loss = loss_fn(LHS - RHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabf443b-35ed-4a6d-b180-08694e7ec7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
